# Content

Configuration files and code to prepare the data for the Mask-RCNN algorithm as implemented by [matterport](https://github.com/matterport/Mask_RCNN)

Folder contents:

  * **Apply MaskRCNN on video.py**: Apply a trained model to all the video's int eh provided folder.
  * **Construct COCO annotations - v2.py**: Construct the annotations file required for training based on the individual mask for each monster.
  * **Construct COCO annotations.py (deprecated)**: The first attempt used one mask per image where each monster type had a different color. However there were two issues with this approach:
    1. The colors in the mask generated by UE4 did not correspond entirely with the input colors and there were slight changes over serveral masks as well. This resulted in a complicated post-processing. In rare cases it may even have lead to misinterpreting a mask for one monster type as another monster type and thus polluting the training data.
	1. It was not possible to distinguish masks if two monsters of the same type overlapped. As a precaution I filtered all images with duplicate monsters. As a result the usable training data was less than the generated data.
  * **Train MaskRCNN with custom dataset.py**: Script to train a pre-trained model on the dataset.
  * **Visualise COCO dataset.py**: Visualize the dataset.

# Instructions

To train the Mask-RCNN model:

  1. Install the python package ```mrcnn```.
  1. Set the correct paths in the config in the training script.
  1. Execute the training script.